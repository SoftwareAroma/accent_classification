{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import utils\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = \"../../bio_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_audio(MFCCs, model):\n",
    "    '''\n",
    "        Predict class based on MFCC samples\n",
    "        :param MFCCs: Numpy array of MFCCs\n",
    "        :param model: Trained model\n",
    "        :return: Predicted class of MFCC segment group\n",
    "    '''\n",
    "    print(MFCCs.shape)\n",
    "    MFCCs = MFCCs.reshape(MFCCs.shape[0],MFCCs.shape[1], MFCCs.shape[2],1)  # MFCCs.shape[2]\n",
    "    y_predicted = model.predict(MFCCs,verbose=0)\n",
    "    return(Counter(list(y_predicted)).most_common(1)[0][0]) # [0]\n",
    "\n",
    "\n",
    "def predict_prob_class_audio(MFCCs, model):\n",
    "    '''\n",
    "        Predict class based on MFCC samples' probabilities\n",
    "        :param MFCCs: Numpy array of MFCCs\n",
    "        :param model: Trained model\n",
    "        :return: Predicted class of MFCC segment group\n",
    "    '''\n",
    "    MFCCs = MFCCs.reshape(MFCCs.shape[0],MFCCs.shape[1],MFCCs.shape[2],1)\n",
    "    y_predicted = model.predict_proba(MFCCs,verbose=0)\n",
    "    return(np.argmax(np.sum(y_predicted,axis=0)))\n",
    "\n",
    "def predict_class_all(X_train, model):\n",
    "    '''\n",
    "        :param X_train: List of segmented mfccs\n",
    "        :param model: trained model\n",
    "        :return: list of predictions\n",
    "    '''\n",
    "    predictions = []\n",
    "    for mfcc in X_train:\n",
    "        predictions.append(predict_class_audio(mfcc, model))\n",
    "        # predictions.append(predict_prob_class_audio(mfcc, model))\n",
    "    return predictions\n",
    "\n",
    "def confusion_matrix(y_predicted,y_test):\n",
    "    '''\n",
    "        Create confusion matrix\n",
    "        :param y_predicted: list of predictions\n",
    "        :param y_test: numpy array of shape (len(y_test), number of classes). 1.'s at index of actual, otherwise 0.\n",
    "        :return: numpy array. confusion matrix\n",
    "    '''\n",
    "    confusion_matrix = np.zeros((len(y_test[0]),len(y_test[0])),dtype=int )\n",
    "    for index, predicted in enumerate(y_predicted):\n",
    "        confusion_matrix[np.argmax(y_test[index])][predicted] += 1\n",
    "    return(confusion_matrix)\n",
    "\n",
    "def get_accuracy(y_predicted,y_test):\n",
    "    '''\n",
    "        Get accuracy\n",
    "        :param y_predicted: numpy array of predictions\n",
    "        :param y_test: numpy array of actual\n",
    "        :return: accuracy\n",
    "    '''\n",
    "    c_matrix = confusion_matrix(y_predicted,y_test)\n",
    "    return( np.sum(c_matrix.diagonal()) / float(np.sum(c_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_df(df):\n",
    "    '''\n",
    "        Function to filter audio files based on df columns\n",
    "        df column options: [age,age_of_english_onset,age_sex,birth_place,english_learning_method,\n",
    "        english_residence,length_of_english_residence,native_language,other_languages,sex]\n",
    "        :param df (DataFrame): Full unfiltered DataFrame\n",
    "        :return (DataFrame): Filtered DataFrame\n",
    "    '''\n",
    "    arabic = df[df.native_language == 'arabic']\n",
    "    mandarin = df[df.native_language == 'mandarin']\n",
    "    english = df[df.native_language == 'english']\n",
    "    mandarin = mandarin[mandarin.length_of_english_residence < 2] # 10\n",
    "    arabic = arabic[arabic.length_of_english_residence < 2] # 10\n",
    "\n",
    "    # use concat to add the dataframes together\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            mandarin,\n",
    "            arabic,\n",
    "            english,\n",
    "        ],\n",
    "        ignore_index=True\n",
    "    )\n",
    "    # return dataframe\n",
    "\n",
    "def split_people(df,test_size=0.2):\n",
    "    '''\n",
    "        Create train test split of DataFrame\n",
    "        :param df (DataFrame): Pandas DataFrame of audio files to be split\n",
    "        :param test_size (float): Percentage of total files to be split into test\n",
    "        :return X_train, X_test, y_train, y_test (tuple): Xs are list of df['language_num'] and Ys are df['native_language']\n",
    "    '''\n",
    "    return train_test_split(\n",
    "        df['language_num'],\n",
    "        df['native_language'],\n",
    "        test_size=test_size,\n",
    "        random_state=124\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_acoustic_features(file_path, features=('mfcc', 'chroma_stft', 'spectral_centroid')):\n",
    "    \"\"\"\n",
    "        Extracts acoustic features from an audio file.\n",
    "        Args:\n",
    "            file_path (str): Path to the audio file.\n",
    "            features (tuple, optional): A tuple of feature names to extract. Defaults to ('mfcc', 'chroma_stft', 'spectral_centroid').\n",
    "        Returns:\n",
    "            dict: A dictionary containing the extracted acoustic features, or None if an error occurs.\n",
    "        Raises:\n",
    "            ValueError: If an unsupported feature is requested.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(f'../../data/audio/{file_path}.wav')\n",
    "        features_dict = {}\n",
    "        for feature_name in features:\n",
    "            if feature_name == 'mfcc':\n",
    "                features_dict['mfcc'] = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "            elif feature_name == 'chroma_stft':\n",
    "                features_dict['chroma_stft'] = librosa.feature.chroma_stft(y=y, sr=sr, n_chroma=12)\n",
    "            elif feature_name == 'spectral_centroid':\n",
    "                features_dict['spectral_centroid'] = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            elif feature_name == 'spectral_bandwidth':\n",
    "                features_dict['spectral_bandwidth'] = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            elif feature_name == 'zero_crossing_rate':\n",
    "                features_dict['zero_crossing_rate'] = librosa.feature.zero_crossing_rate(\n",
    "                y=y, \n",
    "                frame_length=2048, \n",
    "                hop_length=512\n",
    "            )\n",
    "            elif feature_name == 'rmse':\n",
    "                features_dict['rmse'] = librosa.feature.rms(y=y)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported feature: {feature_name}\")\n",
    "\n",
    "        return features_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None  # Or handle error differently\n",
    "\n",
    "\n",
    "def extract_prosodic_features(file_path, features=('pitch', 'intensity', 'duration')):\n",
    "    \"\"\"\n",
    "        Extracts prosodic features from an audio file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the audio file.\n",
    "            features (tuple, optional): A tuple of feature names to extract. Defaults to ('pitch', 'intensity', 'duration').\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the extracted prosodic features.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported feature is requested.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(f'../../data/audio/{file_path}.wav')\n",
    "        prosodic_features = {}\n",
    "        for feature_name in features:\n",
    "            if feature_name == 'pitch':\n",
    "                prosodic_features['pitch'] = librosa.yin(y=y, fmin=65, fmax=2093)\n",
    "            elif feature_name == 'intensity':\n",
    "                prosodic_features['intensity'] = librosa.feature.rms(y=y)\n",
    "            elif feature_name == 'duration':\n",
    "                prosodic_features['duration'] = len(y) / sr\n",
    "            elif feature_name == 'formants':\n",
    "                # Implement formant extraction using librosa or a custom solution\n",
    "                prosodic_features['formants'] = None  # Placeholder for now\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported feature: {feature_name}\")\n",
    "        return prosodic_features\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None  # Handle loading errors\n",
    "\n",
    "# extract plp \n",
    "def extract_plp(file_path):\n",
    "    y, sr = librosa.load(f'../../data/audio/{file_path}.wav')\n",
    "    plp = librosa.beat.plp(y=y, sr=sr)\n",
    "    return plp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = CSV_FILE_PATH\n",
    "df = pd.read_csv(csv_file)\n",
    "filtered_df = filter_df(df)\n",
    "split_peo = split_people(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "SILENCE_THRESHOLD = .001 # .01\n",
    "RATE = 2205 # 2205\n",
    "N_MFCC = 15 #13 #15 # 20\n",
    "COL_SIZE = 30\n",
    "EPOCHS = 10 #35 #250\n",
    "BATCH_SIZE=16\n",
    "\n",
    "def to_categorical(y):\n",
    "    '''\n",
    "        Converts list of languages into a binary class matrix\n",
    "        :param y (list): list of languages\n",
    "        :return (numpy array): binary class matrix\n",
    "    '''\n",
    "    lang_dict = {}\n",
    "    for index,language in enumerate(set(y)):\n",
    "        # # strip the numbers from the language name, example english1 -> english\n",
    "        # language = re.sub(r'[0-9]+', '', language)\n",
    "        # # split by new line and take the first part\n",
    "        # language = language.split('\\n')[0]\n",
    "        lang_dict[language] = index\n",
    "    y = list(map(lambda x: lang_dict[x],y))\n",
    "    return utils.to_categorical(y, len(lang_dict))\n",
    "\n",
    "def get_wav(filename):\n",
    "    \"\"\"\n",
    "        Loads a wav file from disk and resamples to a target sample rate.\n",
    "\n",
    "        Args:\n",
    "            filename (str): Path to the wav file.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Down-sampled wav file (or None if an error occurs).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(f'../../data/audio/{filename}.wav')\n",
    "        return librosa.core.resample(y=y, orig_sr=sr, target_sr=RATE, scale=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading wav: {filename} - {e}\")\n",
    "        return None  # Or handle error differently\n",
    "\n",
    "def to_mfcc(wav):  # Optional arguments for flexibility\n",
    "    \"\"\"\n",
    "        Converts a wav file to Mel Frequency Ceptral Coefficients (MFCCs).\n",
    "        Args:\n",
    "            wav (numpy array): The wav form data.\n",
    "            sr (int, optional): The sample rate of the audio. Defaults to None (use from data if available).\n",
    "            n_mfcc (int, optional): The number of MFCC coefficients to extract. Defaults to None (use librosa's default).\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: A 2D numpy array containing the MFCC features.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs during processing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return librosa.feature.mfcc(y=wav, sr=RATE, n_mfcc=N_MFCC)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting wav to MFCC: {e}\")\n",
    "        return None  # Or handle error differently\n",
    "\n",
    "\n",
    "\n",
    "def remove_silence(wav, thresh=0.04, chunk=5000):\n",
    "    '''\n",
    "        Searches wav form for segments of silence. If wav form values are lower than 'thresh' for 'chunk' samples, the values will be removed\n",
    "        :param wav (np array): Wav array to be filtered\n",
    "        :return (np array): Wav array with silence removed\n",
    "    '''\n",
    "\n",
    "    tf_list = []\n",
    "    for x in range(len(wav) / chunk):\n",
    "        if (np.any(wav[chunk * x:chunk * (x + 1)] >= thresh) or np.any(wav[chunk * x:chunk * (x + 1)] <= -thresh)):\n",
    "            tf_list.extend([True] * chunk)\n",
    "        else:\n",
    "            tf_list.extend([False] * chunk)\n",
    "\n",
    "    tf_list.extend((len(wav) - len(tf_list)) * [False])\n",
    "    return(wav[tf_list])\n",
    "\n",
    "def normalize_mfcc(mfcc):\n",
    "    '''\n",
    "        Normalize mfcc\n",
    "        :param mfcc:\n",
    "        :return:\n",
    "    '''\n",
    "    mms = MinMaxScaler()\n",
    "    return(mms.fit_transform(np.abs(mfcc)))\n",
    "\n",
    "def make_segments(mfccs,labels):\n",
    "    '''\n",
    "        Makes segments of mfccs and attaches them to the labels\n",
    "        :param mfccs: list of mfccs\n",
    "        :param labels: list of labels\n",
    "        :return (tuple): Segments with labels\n",
    "    '''\n",
    "    segments = []\n",
    "    seg_labels = []\n",
    "    for mfcc,label in zip(mfccs,labels):\n",
    "        for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "            segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "            seg_labels.append(label)\n",
    "    return(segments, seg_labels)\n",
    "\n",
    "def segment_one(mfcc):\n",
    "    '''\n",
    "        Creates segments from on mfcc image. If last segments is not long enough to be length of columns divided by COL_SIZE\n",
    "        :param mfcc (numpy array): MFCC array\n",
    "        :return (numpy array): Segmented MFCC array\n",
    "    '''\n",
    "    segments = []\n",
    "    for start in range(0, int(mfcc.shape[1] / COL_SIZE)):\n",
    "        segments.append(mfcc[:, start * COL_SIZE:(start + 1) * COL_SIZE])\n",
    "    return(np.array(segments))\n",
    "\n",
    "def create_segmented_mfccs(X_train):\n",
    "    '''\n",
    "        Creates segmented MFCCs from X_train\n",
    "        :param X_train: list of MFCCs\n",
    "        :return: segmented mfccs\n",
    "    '''\n",
    "    segmented_mfccs = []\n",
    "    for mfcc in X_train:\n",
    "        # print(\"were here >>>> \", mfcc.shape)\n",
    "        segmented_mfccs.append(segment_one(mfcc))\n",
    "    return(segmented_mfccs)\n",
    "\n",
    "\n",
    "def train_model(X_train,y_train,X_validation, y_validation, batch_size=BATCH_SIZE):\n",
    "    '''\n",
    "        Trains 2D convolutional neural network\n",
    "        :param X_train: Numpy array of mfccs\n",
    "        :param y_train: Binary matrix based on labels\n",
    "        :return: Trained model\n",
    "    '''\n",
    "    # Get row, column, and class sizes\n",
    "    rows = X_train[0].shape[0]\n",
    "    cols = X_train[0].shape[1]\n",
    "    val_rows = X_validation[0].shape[0]\n",
    "    val_cols = X_validation[0].shape[1]\n",
    "    num_classes = len(y_train[0])\n",
    "    input_shape = (rows, cols, 1)\n",
    "    X_train = X_train.reshape(X_train.shape[0], rows, cols, 1 )\n",
    "    X_validation = X_validation.reshape(X_validation.shape[0],val_rows,val_cols,1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            32, \n",
    "            kernel_size=(3,3), \n",
    "            activation='relu',\n",
    "            data_format=\"channels_last\",\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    )\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adadelta',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    # Stops training if accuracy does not change at least 0.005 over 10 epochs\n",
    "    es = EarlyStopping(\n",
    "        monitor='acc', \n",
    "        min_delta=.005,\n",
    "        patience=10, \n",
    "        verbose=1, \n",
    "        mode='auto'\n",
    "    )\n",
    "    # Creates log file for graphical interpretation using TensorBoard\n",
    "    tb = TensorBoard(\n",
    "        log_dir='../../logs', \n",
    "        histogram_freq=0, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        write_graph=True, \n",
    "        write_grads=True,\n",
    "        write_images=True, \n",
    "        embeddings_freq=0, \n",
    "        embeddings_layer_names=None,\n",
    "        embeddings_metadata=None,\n",
    "    )\n",
    "\n",
    "    # Image shifting\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.05)\n",
    "\n",
    "    # Fit model using ImageDataGenerator\n",
    "    model.fit(\n",
    "        datagen.flow(\n",
    "            X_train, \n",
    "            y_train,\n",
    "            # batch_size=batch_size\n",
    "        ),\n",
    "        steps_per_epoch=len(X_train) / BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            # es,\n",
    "            tb\n",
    "        ],\n",
    "        validation_data=(\n",
    "            X_validation,\n",
    "            y_validation\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return (model)\n",
    "\n",
    "def save_model(model, model_filename):\n",
    "    '''\n",
    "        Save model to file\n",
    "        :param model: Trained model to be saved\n",
    "        :param model_filename: Filename\n",
    "        :return: None\n",
    "    '''\n",
    "    model.save('../../output/models/{}.keras'.format(model_filename))  # creates a HDF5 file 'my_model.keras'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arguments\n",
    "file_name = CSV_FILE_PATH\n",
    "model_filename = 'model5'\n",
    "# Load metadata\n",
    "df = pd.read_csv(file_name)\n",
    "# Filter metadata to retrieve only files desired\n",
    "filtered_df = filter_df(df)\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = split_people(filtered_df)\n",
    "# split y_train value by \\n and take the first part, in the dataframe\n",
    "y_test = y_test.apply(lambda x: x.split('\\n')[0])\n",
    "y_train = y_train.apply(lambda x: x.split('\\n')[0])\n",
    "# Get statistics\n",
    "train_count = Counter(y_train)\n",
    "test_count = Counter(y_test)\n",
    "print('Train count:', train_count)\n",
    "print('Test count:', test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_to_beat = test_count.most_common(1)[0][1] / float(np.sum(list(test_count.values())))\n",
    "\n",
    "# To categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get resampled wav files using multiprocessing\n",
    "if DEBUG:\n",
    "    print('Extracting Features....')\n",
    "    \n",
    "with ThreadPoolExecutor() as pool:\n",
    "    X_prosodic = pool.map(extract_prosodic_features, X_train)\n",
    "    X_acoustic = pool.map(extract_acoustic_features, X_train)\n",
    "    X_plp = pool.map(extract_plp, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do something with the prosodic features\n",
    "# ...\n",
    "\n",
    "# do something with the acoustic features\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get resampled wav files using multiprocessing\n",
    "if DEBUG:\n",
    "    print('Loading wav files....')\n",
    "# pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "# X_train = pool.map(get_wav, X_train)\n",
    "# X_test = pool.map(get_wav, X_test)\n",
    "\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    X_train = pool.map(get_wav, X_train)\n",
    "    X_test = pool.map(get_wav, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to MFCC\n",
    "if DEBUG:\n",
    "    print('Converting to MFCC....')\n",
    "with ThreadPoolExecutor() as pool:\n",
    "    X_train = pool.map(to_mfcc, X_train)\n",
    "    X_test = pool.map(to_mfcc, X_test)\n",
    "    # X_train = pool.map(to_mfcc, X_train)\n",
    "    # X_test = pool.map(to_mfcc, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create segments from MFCCs\n",
    "X_train, y_train = make_segments(X_train, y_train)\n",
    "X_validation, y_validation = make_segments(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = train_model(np.array(X_train), np.array(y_train), np.array(X_validation),np.array(y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rows = X_validation[0].shape[0]\n",
    "val_cols = X_validation[0].shape[1]\n",
    "X_validation = np.array(X_validation)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0],val_rows,val_cols, 1)\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for mfcc in X_validation:\n",
    "    # print(mfcc.shape)\n",
    "    \n",
    "    # MFCCs = mfcc.reshape(mfcc.shape[0], mfcc.shape[1], mfcc.shape[2])  # MFCCs.shape[2]\n",
    "    # print(MFCCs.shape)\n",
    "    # print(mfcc.shape[0],mfcc.shape[1])\n",
    "    # reshare mfcc to get this shape format shape=(None, 15, 30, 1), 1 is the number of channels\n",
    "    # mfcc = mfcc.reshape(mfcc.shape[0],mfcc.shape[1],mfcc.shape[2])  # MFCCs.shape[2]\n",
    "    # y_predicted = model.predict(mfcc,verbose=0)\n",
    "    # print(Counter(list(y_predicted)).most_common(1)[0]) # [0] shape=(None, 15, 30, 1)\n",
    "    # return(Counter(list(y_predicted)).most_common(1)[0]) # [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on full X_test MFCCs\n",
    "X_val = create_segmented_mfccs(X_test)\n",
    "y_predicted = predict_class_all(X_validation, model)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some X_test samples sinces its a generator not a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics\n",
    "print('Training samples:', train_count)\n",
    "print('Testing samples:', test_count)\n",
    "print('Accuracy to beat:', acc_to_beat)\n",
    "print('Confusion matrix of total samples:\\n', np.sum(confusion_matrix(y_predicted, y_test),axis=1))\n",
    "print('Confusion matrix:\\n',confusion_matrix(y_predicted, y_test))\n",
    "print('Accuracy:', get_accuracy(y_predicted,y_test))\n",
    "\n",
    "# Save model\n",
    "save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# get the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_predicted, y_test)\n",
    "\n",
    "# plot using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# save it to file\n",
    "plt.savefig('../../output/confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=f'../../output/model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True,\n",
    "    show_layer_activations=True,\n",
    "    show_trainable=True,\n",
    "    dpi=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
